GNU Radio Web Scraper

1. Good curl reference:
	http://www.yilmazhuseyin.com/blog/dev/curl-tutorial-examples-usage/
	
2. curl the main archive of the mailing list like this:
	curl --request GET http://lists.gnu.org/archive/html/discuss-gnuradio/
	
3. now try to do the same thing by wrapping these curl commands in a c++
library that links against libcurl

NOTE: I need to add a comment to my tips & hints page.  Read the man page for
'date' and 'strftime'.  Then from textMate I can hit 'ctrl r' to run a date command
in the shell and return the date.

4. forked the repo at: 
	https://github.com/JosephP91/curlcpp
and couldn't build it because of dependencies on '-std=c++11' somewhere in the
make process.  I wasn't going to dig for this so I moved on to look for a simpler
wrapper.

5. forked the repo at:
	https://github.com/gsauthof/ccurl
and it worked great.  ran make in the source directory and it made an executable name
test.  Test takes a single argument on the command line of the url you want to 
curl and returns the result to stdout.  I invoked with:
	./test http://lists.gnu.org/archive/html/discuss-gnuradio/
and it successfully pulled the page for me.  Then I invoked with 
	./test http://lists.gnu.org/archive/html/discuss-gnuradio/ > gnu_front_page.txt
and it successfully saved the page into the gnu_front_page.txt file.

6. Now I have a way to curl the front page and save it to a file.  The next step is
to process that file line by line.  Towards the bottom there is a table that lists 
all the links to each month's worth of discussion topics.  I need to run the file through 
a regex search and build another file with a URL on each line.

7. I can manually scan the front_page and keep the output to five lines with this:
	grep --max-count=5 '<li>' front_page.html
	
8. Now I need to find a regex example to do this in my c++ code.

9. Since my laptop doesn't have c++11 with native regex support I need to use the
Boost.org regex library which requires that I build it since it's not just a header
only supported function.  The link below is a great reference..well written, good
grammer and spot on step-by-step instructions
	http://www.boost.org/doc/libs/1_55_0/more/getting_started/unix-variants.html

10. To get started I need to refresh my memory on using the header only libs.  See
boost_lambda.cpp to see this.

11. Now I need to build against a library.  I haven't done this, so it will be a
learning curve. Boost comes with a bootstrap program that guides the build process
for their many libs.  invoke it first with help then with --show-libraries.  I had
to run it with sudo.  
	cd /usr/local/boost_1_55_0
	./bootstrap.sh --help | more
	sudo ./bootstrap.sh --show-libraries | more
since I only want to regex library for now I invoked the bootstrap like this:
	sudo ./bootstrap.sh --with-libraries=regex
this command exited with a successful build and created a configuration script that
is invoked by running 
	./b2
however, it also has a help option so I want to look at that first by calling
	./b2 --help
after reading a little about how ./b2 works I called it like this
	sudo ./b2
the build script exits with the following message:
	The Boost C++ Libraries were successfully built!
	The following directory should be added to compiler include paths:
	    /usr/local/boost_1_55_0
	The following directory should be added to linker library paths:
	    /usr/local/boost_1_55_0/stage/lib
	FINALLY, I was able to compile the test program boost_regex.cpp with this line:
		c++ -I/usr/local/boost_1_55_0 /usr/local/boost_1_55_0/stage/lib/libboost_regex.a boost_regex.cpp  -o a_example
		
12. After this lengthy process to get REGEX running in my version of C++ I was
able to successfully run the test program by feeding a sample text email into it
and the regex found the subject line and returned it to std out.  Note the calling
syntax for the command line..kind of cool
	./a_example < test_mail.txt

13. Now that I have the foundation in place after nine hours..hahaha..I'm starting to 
work on my main.cpp.  Successfully building with this directive
	c++ -lcurl ccurl/curl.cpp gr_scraper.cpp
	
14. 

	